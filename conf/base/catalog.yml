# Here you can define all your datasets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html
apartments_partitioned:
  type: partitions.PartitionedDataset
  path: data/01_raw/dataset
  dataset: pandas.CSVDataset
  filename_suffix: ".csv"

concatenated_apartments:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/concatenated_apartments.csv

intermediate_imputed_apartments:
  type: pandas.CSVDataset
  filepath: data/02_intermediate/imputed_apartments.csv

primary_apartments:
  type: pandas.CSVDataset
  filepath: data/03_primary/primary_apartments.csv

primary_normalized_apartments:
  type: pandas.CSVDataset
  filepath: data/03_primary/primary_normalized_apartments.csv

train_data:
  type: pandas.CSVDataset
  filepath: data/04_model_input/train_data.csv

test_data:
  type: pandas.CSVDataset
  filepath: data/04_model_input/test_data.csv

predictions:
  type: pandas.CSVDataset
  filepath: data/05_model_output/predictions.csv

trained_model:
  type: pickle.PickleDataset
  filepath: data/06_models/autogluon/predictor.pkl